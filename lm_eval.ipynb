{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops sentencepiece torch transformers\n",
    "\n",
    "!git clone https://github.com/EleutherAI/lm-evaluation-harness.git\n",
    "\n",
    "%cd lm-evaluation-harness\n",
    "\n",
    "!pip install .\n",
    "import os\n",
    "os.environ[\"HF_ALLOW_CODE_EVAL\"] = \"1\"\n",
    "\n",
    "model = \"Qwen/Qwen2.5-Coder-0.5B-Instruct\"\n",
    "\n",
    "tasks = [\n",
    "    \"global_mmlu_full_sv_machine_learning\",\n",
    "    \"global_mmlu_full_sv_formal_logic\",\n",
    "    \"global_mmlu_full_sv_machine_learning\",\n",
    "    \"global_mmlu_full_uk_college_computer_science\",\n",
    "    \"global_mmlu_full_uk_computer_security\",\n",
    "    \"humaneval_instruct\",\n",
    "    \"humaneval_plus\",\n",
    "    \"mbpp\",\n",
    "    \"jsonschema_bench\"\n",
    "]\n",
    "\n",
    "results_dir = \"./results/\"\n",
    "\n",
    "task_str = \",\".join(tasks)\n",
    "\n",
    "!python -m lm_eval \\\n",
    "  --model hf-auto \\\n",
    "  --model_args pretrained={model},dtype=float32,device=cuda \\\n",
    "  --tasks {task_str} \\\n",
    "  --num_fewshot 3 \\\n",
    "  --batch_size 10 \\\n",
    "  --gen_kwargs temperature=0.2,max_new_tokens=512,do_sample=True,num_return_sequences=10 \\\n",
    "  --log_samples \\\n",
    "  --output_path {results_dir} \\\n",
    "  --confirm_run_unsafe_code \\\n",
    "  --apply_chat_template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from glob import glob\n",
    "\n",
    "!ls\n",
    "\n",
    "results_dir = \"./meus_resultados\"\n",
    "csv_file = \"result.csv\"\n",
    "\n",
    "def extract_fields(data, file_name):\n",
    "    task_key = next(iter(data.get(\"results\", {})), None)  \n",
    "    task_data = data.get(\"results\", {}).get(task_key, {}) if task_key else {}\n",
    "\n",
    "    return {\n",
    "        \"file_name\": file_name,\n",
    "        \"model_name_sanitized\": data.get(\"model_name_sanitized\"),\n",
    "        \"alias\": task_data.get(\"alias\"),\n",
    "        \"acc\": task_data.get(\"acc,none\"),\n",
    "        \"acc_stderr\": task_data.get(\"acc_stderr,none\")\n",
    "    }\n",
    "\n",
    "existing_files = set()\n",
    "if os.path.exists(csv_file):\n",
    "    with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            existing_files.add(row['file_name'])\n",
    "\n",
    "json_files = glob(os.path.join(results_dir, \"**\", \"*.json\"), recursive=True)\n",
    "new_rows = []\n",
    "\n",
    "for file_path in json_files:\n",
    "    file_name = os.path.relpath(file_path, results_dir)\n",
    "    if file_name not in existing_files:\n",
    "        with open(file_path, encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                row = extract_fields(data, file_name)\n",
    "                new_rows.append(row)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"[ERROR] Invalid JSON in: {file_path}\")\n",
    "\n",
    "if new_rows:\n",
    "    file_exists = os.path.exists(csv_file)\n",
    "    with open(csv_file, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"file_name\", \"model_name_sanitized\", \"alias\", \"acc\", \"acc_stderr\"])\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(new_rows)\n",
    "    print(f\"{len(new_rows)} new results added to '{csv_file}'.\")\n",
    "else:\n",
    "    print(\"No new results found.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
